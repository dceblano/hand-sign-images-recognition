{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# Step 1: Import Libraries\n",
    "# ----------------------\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import keras_tuner as kt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# Step 2: Preprocess Data\n",
    "# ----------------------\n",
    "\n",
    "# Training Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalizes pixel values from the range [0, 255] to [0, 1]\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    ")\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    'archive/Train',\n",
    "    target_size=(128, 128),  # Resize to 128x128 pixels (Compatibility to MobileNetV2)\n",
    "    batch_size=64,\n",
    "    class_mode='sparse',  # Sparse categorical labels, returns labels as integers\n",
    "    color_mode='rgb'  # RGB input because MobileNetV2 expects 3-channel RGB input\n",
    ")\n",
    "\n",
    "class_indices = training_set.class_indices  # Get the class label-to-index mapping\n",
    "with open('class_indices.pkl', 'wb') as f:\n",
    "    pickle.dump(class_indices, f)  # Save the mapping to a file\n",
    "\n",
    "print(\"Class indices saved successfully:\", class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map integer class labels back to class names\n",
    "reverse_class_indices = {v: k for k, v in training_set.class_indices.items()}\n",
    "class_names = [reverse_class_indices[label] for label in training_set.classes]\n",
    "\n",
    "# Create a count plot\n",
    "sns.countplot(x=class_names, order=sorted(reverse_class_indices.values()))\n",
    "plt.title(\"Class Distribution in Training Data\")\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.xticks(rotation=90)  # Rotate class names for better visibility\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data Preprocessing\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    'archive/Test',\n",
    "    target_size=(128, 128),  # Match training size\n",
    "    batch_size=64,\n",
    "    class_mode='sparse',     # Sparse categorical labels\n",
    "    color_mode='rgb'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some augmented images\n",
    "x_batch, y_batch = next(training_set)  # Get a batch of training data\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(x_batch[i])  # Display image in its original color format (RGB)\n",
    "    \n",
    "    # Get the class name using the integer label\n",
    "    class_name = reverse_class_indices[y_batch[i]]\n",
    "    \n",
    "    plt.title(f'Class: {class_name}')  # Show class name instead of integer label\n",
    "    plt.axis('off')  # Turn off the axis for a cleaner visualization\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# Step 3: Load Pretrained Model (Feature Extractor)\n",
    "# ----------------------\n",
    "\n",
    "# Load MobileNetV2 pretrained on ImageNet\n",
    "base_model = MobileNetV2(\n",
    "    input_shape=(128, 128, 3),  # MobileNetV2 expects 3-channel RGB input\n",
    "    include_top=False,          # Exclude the classification head, Excludes dense layer, acts as feature extractor\n",
    "    weights='imagenet'          # Use pretrained weights\n",
    ")\n",
    "\n",
    "# Freeze the base model's layers to prevent training\n",
    "base_model.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint(\n",
    "    'best_model.keras',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "'''\n",
    "Dynamically reduces the learning rate when the validation loss plateaus (does not improve for patience epochs).\n",
    "Helps the model converge better in later epochs by fine-tuning weights more cautiously.\n",
    "'''\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau( # Dynamic adjustment of the learning rate during training can lead to better convergence.\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,   # Reduce the learning rate by half\n",
    "    patience=3,   # If no improvement for 3 epochs\n",
    "    min_lr=1e-6   # Set a minimum learning rate\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# Step 4: Build the Model\n",
    "# ----------------------\n",
    "\n",
    "# Add custom layers on top of the pretrained base model\n",
    "# Define a function to build the model\n",
    "def build_model(hp):\n",
    "    model = Sequential([\n",
    "        base_model,  # Pretrained MobileNetV2 as the base model\n",
    "        GlobalAveragePooling2D(),\n",
    "\n",
    "        # Tune the number of units in the first Dense layer\n",
    "        Dense(units=hp.Int('units_1', min_value=128, max_value=512, step=64), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(rate=hp.Float('dropout_1', min_value=0.2, max_value=0.5, step=0.1)),\n",
    "\n",
    "        # Tune the number of units in the second Dense layer\n",
    "        Dense(units=hp.Int('units_2', min_value=64, max_value=256, step=64), activation='relu'),\n",
    "        Dropout(rate=hp.Float('dropout_2', min_value=0.2, max_value=0.5, step=0.1)),\n",
    "\n",
    "        # Final output layer\n",
    "        Dense(24, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Tune the learning rate\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4, 1e-5])\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Define the tuner for hyperparameter search using the Hyperband algorithm\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,          # The function that builds the model with tunable hyperparameters\n",
    "    objective='val_accuracy',  # Optimize the validation accuracy during tuning\n",
    "    max_epochs=3,         # Maximum number of epochs any model can be trained for\n",
    "    factor=3,             # The reduction factor; in each round, only 1/factor models are retained\n",
    "    directory='hyperparameter_tuning',  # Directory to store tuning results\n",
    "    project_name='cnn_asl'              # Name of the project for organizing tuning outputs\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the tuner\n",
    "tuner.search(training_set, validation_data=test_set, callbacks=[model_checkpoint\n",
    "])\n",
    "\n",
    "# Get the best hyperparameters and model\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0] # num_trials retrieves the single best parameter\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "print(f\"Best number of units in the first dense layer: {best_hps.get('units_1')}\")\n",
    "print(f\"Best number of units in the second dense layer: {best_hps.get('units_2')}\")\n",
    "print(f\"Best dropout rate for first layer: {best_hps.get('dropout_1')}\")\n",
    "print(f\"Best dropout rate for second layer: {best_hps.get('dropout_2')}\")\n",
    "print(f\"Best learning rate: {best_hps.get('learning_rate')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect a batch of data from the generator\n",
    "# To confirm shape and format \n",
    "x_batch, y_batch = next(training_set)\n",
    "print(\"Input batch shape (x_batch):\", x_batch.shape)\n",
    "print(\"Label batch shape (y_batch):\", y_batch.shape)\n",
    "training_set.reset()\n",
    "test_set.reset()\n",
    "\n",
    "y_batch = np.argmax(y_batch, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# Step 6: Train the Model\n",
    "# ----------------------\n",
    "\n",
    "# Train the model\n",
    "history = best_model.fit(\n",
    "    training_set,\n",
    "    validation_data=test_set,\n",
    "    epochs=25,\n",
    "    # class_weight = class_weights,\n",
    "    callbacks=[reduce_lr, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# Step 7: Fine Tuning\n",
    "# ----------------------\n",
    "\n",
    "\n",
    "# Unfreeze the base model for fine-tuning\n",
    "base_model.trainable = True\n",
    "\n",
    "\n",
    "# Unfreezing deeper layers since they capture high-level features relevant\n",
    "for layer in base_model.layers[:-50]:  # Freeze all layers except the last 50\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompiling again after changing trainable attributes\n",
    "best_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),  # incerease LR since  frozen layers have already stabilized.\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the model\n",
    "history_finetune = best_model.fit(\n",
    "    training_set,\n",
    "    validation_data=test_set,\n",
    "    epochs=10,  # Train for a few more epochs\n",
    "    callbacks=[model_checkpoint]  # Apply early stopping for best model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_batch = next(training_set)  # Fetch both images and labels\n",
    "X_train = X_train.reshape(len(X_train), -1)  # Flatten images\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_batch:\", y_batch.shape)  # Should be (64,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ----------------------\n",
    "# # Step 5: Model Selection\n",
    "# # ----------------------\n",
    "\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "# import numpy as np\n",
    "\n",
    "# # Extract entire dataset from the generator\n",
    "# X_train_list = []\n",
    "# y_train_list = []\n",
    "\n",
    "# # Iterate through the generator to get all batches\n",
    "# for _ in range(len(training_set)):  # Number of steps per epoch\n",
    "#     X_batch, y_batch = next(training_set)\n",
    "#     X_train_list.append(X_batch.reshape(len(X_batch), -1))  # Flatten images\n",
    "#     y_train_list.append(y_batch)\n",
    "\n",
    "# # Combine all batches into one dataset\n",
    "# X_train = np.vstack(X_train_list)  # Combine all image batches\n",
    "# y_train = np.hstack(y_train_list)  # Combine all label batches\n",
    "\n",
    "# # Check shapes\n",
    "# print(\"Shape of X_train:\", X_train.shape)  # Should be (total_samples, number_of_features)\n",
    "# print(\"Shape of y_train:\", y_train.shape)  # Should be (total_samples,)\n",
    "\n",
    "# # Define Logistic Regression parameters for GridSearchCV\n",
    "# param_grid_lr = {\n",
    "#     'C': [0.1, 1, 10],\n",
    "#     'solver': ['liblinear', 'lbfgs'],\n",
    "#     'max_iter': [100, 200, 500]\n",
    "# }\n",
    "\n",
    "# # Train Logistic Regression with GridSearchCV\n",
    "# lr_model = LogisticRegression()\n",
    "# grid_search_lr = GridSearchCV(estimator=lr_model, param_grid=param_grid_lr, cv=3, scoring='accuracy', verbose=1)\n",
    "# grid_search_lr.fit(X_train, y_train)  # Train on the full dataset\n",
    "\n",
    "# # Display best parameters and training accuracy\n",
    "# print(\"Best Logistic Regression Parameters:\", grid_search_lr.best_params_)\n",
    "# print(\"Best Logistic Regression Accuracy:\", grid_search_lr.best_score_)\n",
    "\n",
    "# # Test the model\n",
    "# X_test, y_test = next(test_set)  # Fetch a batch of test data\n",
    "# X_test = X_test.reshape(len(X_test), -1)  # Flatten test images\n",
    "# y_pred_lr = grid_search_lr.best_estimator_.predict(X_test)\n",
    "\n",
    "# # Evaluate model performance\n",
    "# print(\"Logistic Regression Test Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "# print(classification_report(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "# import numpy as np\n",
    "\n",
    "# # Extract entire dataset from the generator\n",
    "# X_train_list = []\n",
    "# y_train_list = []\n",
    "\n",
    "# # Iterate through the generator to get all batches\n",
    "# for _ in range(len(training_set)):  # Number of steps per epoch\n",
    "#     X_batch, y_batch = next(training_set)\n",
    "#     X_train_list.append(X_batch.reshape(len(X_batch), -1))  # Flatten images\n",
    "#     y_train_list.append(y_batch)\n",
    "\n",
    "# # Combine all batches into one dataset\n",
    "# X_train = np.vstack(X_train_list)  # Combine all image batches\n",
    "# y_train = np.hstack(y_train_list)  # Combine all label batches\n",
    "\n",
    "# # Check shapes\n",
    "# print(\"Shape of X_train:\", X_train.shape)  # Should be (total_samples, number_of_features)\n",
    "# print(\"Shape of y_train:\", y_train.shape)  # Should be (total_samples,)\n",
    "\n",
    "# # Define hyperparameters for GridSearchCV\n",
    "# param_grid_dt = {\n",
    "#     'criterion': ['gini', 'entropy'],       # Splitting criteria\n",
    "#     'max_depth': [10, 20, 30, None],        # Maximum depth of the tree\n",
    "#     'min_samples_split': [2, 5, 10],        # Minimum samples required to split\n",
    "#     'min_samples_leaf': [1, 2, 4]           # Minimum samples per leaf node\n",
    "# }\n",
    "\n",
    "# # Initialize Decision Tree model\n",
    "# dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# # GridSearchCV to find the best parameters\n",
    "# grid_search_dt = GridSearchCV(estimator=dt_model, param_grid=param_grid_dt, cv=3, scoring='accuracy', verbose=1)\n",
    "# grid_search_dt.fit(X_train, y_train)  # Train on the entire dataset\n",
    "\n",
    "# # Display best parameters and training accuracy\n",
    "# print(\"Best Decision Tree Parameters:\", grid_search_dt.best_params_)\n",
    "# print(\"Best Decision Tree Accuracy:\", grid_search_dt.best_score_)\n",
    "\n",
    "# # Test the model\n",
    "# X_test_list = []\n",
    "# y_test_list = []\n",
    "\n",
    "# # Extract entire test dataset\n",
    "# for _ in range(len(test_set)):\n",
    "#     X_batch, y_batch = next(test_set)\n",
    "#     X_test_list.append(X_batch.reshape(len(X_batch), -1))  # Flatten test images\n",
    "#     y_test_list.append(y_batch)\n",
    "\n",
    "# # Combine test batches\n",
    "# X_test = np.vstack(X_test_list)\n",
    "# y_test = np.hstack(y_test_list)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# dt_best_model = grid_search_dt.best_estimator_\n",
    "# y_pred_dt = dt_best_model.predict(X_test)\n",
    "\n",
    "# # Evaluate model performance\n",
    "# print(\"Decision Tree Test Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "# print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------\n",
    "# Predict on Entire Test Dataset\n",
    "# -------------------------------\n",
    "\n",
    "# Initialize arrays for true labels and predictions\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Loop through the test dataset in batches\n",
    "for images, labels in test_set:\n",
    "    predictions = best_model.predict(images)  # Get predictions\n",
    "    predicted_classes = np.argmax(predictions, axis=1)  # Convert probabilities to class indices\n",
    "    true_labels.extend(labels)  # Store true labels\n",
    "    predicted_labels.extend(predicted_classes)  # Store predicted labels\n",
    "\n",
    "    # Break after processing all test data (important for generators)\n",
    "    if len(true_labels) >= test_set.samples:\n",
    "        break\n",
    "\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Confusion Matrix\n",
    "# -------------------------------\n",
    "\n",
    "# Compute and display confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(training_set.class_indices.keys()))\n",
    "\n",
    "# Adjust figure size before plotting\n",
    "plt.figure(figsize=(10,10))  # Adjust the width and height as needed\n",
    "disp.plot(cmap='viridis', xticks_rotation='vertical', values_format='d')\n",
    "\n",
    "# Add title and show plot\n",
    "plt.title('Confusion Matrix', fontsize=20)\n",
    "plt.xlabel('Predicted Labels', fontsize=14)\n",
    "plt.ylabel('True Labels', fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Classification Report\n",
    "# -------------------------------\n",
    "# Generate classification metrics\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=list(training_set.class_indices.keys())))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Display predictions on test images\n",
    "plt.figure(figsize=(10, 10))\n",
    "test_images, test_labels = next(test_set)  # Get a batch of test data\n",
    "predictions = best_model.predict(test_images)\n",
    "\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(test_images[i])  # Display in original color format (e.g., RGB)\n",
    "\n",
    "    # Get predicted and true labels as class names\n",
    "    predicted_index = np.argmax(predictions[i])\n",
    "    predicted_label = reverse_class_indices[predicted_index]\n",
    "    true_label = reverse_class_indices[test_labels[i]]\n",
    "\n",
    "    plt.title(f'Pred: {predicted_label}, True: {true_label}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "history_finetune_dict = history_finetune.history\n",
    "\n",
    "# Extract accuracy and loss for training and validation\n",
    "fine_tune_train_acc = history_finetune_dict['accuracy']\n",
    "fine_tune_val_acc = history_finetune_dict['val_accuracy']\n",
    "fine_tune_train_loss = history_finetune_dict['loss']\n",
    "fine_tune_val_loss = history_finetune_dict['val_loss']\n",
    "\n",
    "# Define the number of epochs\n",
    "fine_tune_epochs = range(1, len(fine_tune_train_acc) + 1)\n",
    "\n",
    "# Set figure size and style\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fine_tune_epochs, fine_tune_train_acc, label='Training Accuracy (Fine-tuning)', color='blue')\n",
    "plt.plot(fine_tune_epochs, fine_tune_val_acc, label='Validation Accuracy (Fine-tuning)', color='orange')\n",
    "plt.title('Fine-Tuning: Training and Validation Accuracy', fontsize=14)\n",
    "plt.xlabel('Epochs', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(fine_tune_epochs, fine_tune_train_loss, label='Training Loss (Fine-tuning)', color='blue')\n",
    "plt.plot(fine_tune_epochs, fine_tune_val_loss, label='Validation Loss (Fine-tuning)', color='orange')\n",
    "plt.title('Fine-Tuning: Training and Validation Loss', fontsize=14)\n",
    "plt.xlabel('Epochs', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save CNN model\n",
    "best_model.save('cnn_model.h5')\n",
    "\n",
    "# # Save Logistic Regression model\n",
    "# with open('logistic_regression_model.pkl', 'wb') as f:\n",
    "#     pickle.dump(grid_search_lr.best_estimator_, f)\n",
    "\n",
    "# # Save Decision Tree model\n",
    "# with open('decision_tree_model.pkl', 'wb') as f:\n",
    "#     pickle.dump(grid_search_dt.best_estimator_, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# Step 11: Predict on Outside Data\n",
    "# ----------------------\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "def predict_outside_image(image_path, model, class_indices):\n",
    "    # Step 1: Load and preprocess the image\n",
    "    test_image = image.load_img(image_path, target_size=(128, 128), color_mode='rgb')  # Resize to match model input\n",
    "    test_image = image.img_to_array(test_image) / 255.0  # Normalize to [0, 1]\n",
    "    test_image = np.expand_dims(test_image, axis=0)      # Add batch dimension\n",
    "\n",
    "    # Step 2: Predict\n",
    "    result = model.predict(test_image)\n",
    "    predicted_class_index = np.argmax(result)\n",
    "\n",
    "    # Step 3: Map prediction back to class label\n",
    "    reverse_class_indices = {v: k for k, v in class_indices.items()}\n",
    "    predicted_label = reverse_class_indices[predicted_class_index]\n",
    "\n",
    "    # Step 4: Combine class labels and probabilities, then sort and select top 5\n",
    "    probabilities = {reverse_class_indices[i]: prob for i, prob in enumerate(result[0])}\n",
    "    top_5_predictions = sorted(probabilities.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "\n",
    "    # Step 5: Print the predicted label and top 5 class probabilities\n",
    "    print(f\"Predicted Label: {predicted_label}\")\n",
    "    print(\"Top 5 Class Probabilities:\")\n",
    "    for label, prob in top_5_predictions:\n",
    "        print(f\"  {label}: {prob:.2f}\")\n",
    "\n",
    "# Example usage\n",
    "predict_outside_image('archive/Prediction/L.jpg', best_model, training_set.class_indices)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
